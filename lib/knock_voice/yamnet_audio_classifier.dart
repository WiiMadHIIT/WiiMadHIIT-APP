import 'dart:math';
import 'dart:convert';
import 'dart:typed_data';
import 'package:tflite_flutter/tflite_flutter.dart' hide List;
import 'package:flutter_sound/flutter_sound.dart';
import 'package:flutter/services.dart' show rootBundle;

/// YAMNet Audio Classifier - éŸ³é¢‘åˆ†ç±»å™¨
/// ä½¿ç”¨ YAMNet TFLite æ¨¡å‹è¿›è¡ŒéŸ³é¢‘åˆ†ç±»
class YamnetAudioClassifier {
  Interpreter? _interpreter;
  FlutterSoundRecorder? _recorder;
  List<String>? _labels;
  
  // YAMNet æ¨¡å‹é…ç½®
  static const int _sampleRate = 16000;
  static const int _frameSize = 400; // 25ms at 16kHz
  static const int _hopSize = 160;   // 10ms at 16kHz
  static const int _numMels = 64;
  static const int _numClasses = 521;

  YamnetAudioClassifier() {
    _recorder = FlutterSoundRecorder();
  }

  /// åŠ è½½ TFLite æ¨¡å‹å’Œæ ‡ç­¾
  Future<void> loadModel() async {
    try {
      // åŠ è½½æ¨¡å‹
      _interpreter = await Interpreter.fromAsset('assets/model/yamnet.tflite');
      print('ğŸ¯ YAMNet model loaded successfully');
      
      // åŠ è½½æ ‡ç­¾
      await _loadLabels();
      
      var inputShape = _interpreter!.getInputTensor(0).shape;
      var outputShape = _interpreter!.getOutputTensor(0).shape;
      print('ğŸ¯ Model input shape: $inputShape');
      print('ğŸ¯ Model output shape: $outputShape');
      print('ğŸ¯ Labels loaded: ${_labels?.length} classes');
    } catch (e) {
      print('âŒ Failed to load YAMNet model: $e');
      rethrow;
    }
  }

  /// åŠ è½½æ ‡ç­¾æ–‡ä»¶
  Future<void> _loadLabels() async {
    try {
      String labelsContent = await rootBundle.loadString('assets/model/labels.text');
      _labels = labelsContent.split('\n').where((line) => line.trim().isNotEmpty).toList();
      print('ğŸ¯ Loaded ${_labels!.length} labels');
    } catch (e) {
      print('âŒ Failed to load labels: $e');
      rethrow;
    }
  }

  /// å¼€å§‹å½•éŸ³
  Future<void> startRecording() async {
    try {
      if (_recorder == null) {
        _recorder = FlutterSoundRecorder();
      }
      
      await _recorder!.openRecorder();
      await _recorder!.startRecorder(
        toStream: true,
        codec: Codec.pcm16,
        numChannels: 1,
        sampleRate: _sampleRate,
      );
      print('ğŸ¤ Started recording...');
    } catch (e) {
      print('âŒ Failed to start recording: $e');
      rethrow;
    }
  }

  /// åœæ­¢å½•éŸ³å¹¶è¿”å›éŸ³é¢‘æ•°æ®
  Future<List<double>> stopRecording() async {
    try {
      if (_recorder == null) {
        throw Exception('Recorder not initialized');
      }
      
      String? path = await _recorder!.stopRecorder();
      await _recorder!.closeRecorder();
      
      if (path == null) {
        throw Exception('No recording path returned');
      }
      
      // è¯»å–éŸ³é¢‘æ–‡ä»¶
      Uint8List audioBytes = await _recorder!.readAudioFile(path);
      List<double> audioData = _convertBytesToDoubleList(audioBytes);
      
      print('ğŸ¤ Recording stopped. Audio length: ${audioData.length} samples');
      return audioData;
    } catch (e) {
      print('âŒ Failed to stop recording: $e');
      rethrow;
    }
  }

  /// å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºdoubleåˆ—è¡¨
  List<double> _convertBytesToDoubleList(Uint8List bytes) {
    List<double> audioData = [];
    for (int i = 0; i < bytes.length; i += 2) {
      if (i + 1 < bytes.length) {
        int sample = (bytes[i + 1] << 8) | bytes[i];
        if (sample >= 32768) {
          sample -= 65536;
        }
        audioData.add(sample / 32768.0);
      }
    }
    return audioData;
  }

  /// å¯¹éŸ³é¢‘è¿›è¡Œåˆ†ç±»
  Future<List<MapEntry<String, double>>> classifyAudio(List<double> audioData) async {
    try {
      if (_interpreter == null) {
        throw Exception('Model not loaded. Call loadModel() first.');
      }
      
      if (_labels == null) {
        throw Exception('Labels not loaded.');
      }
      
      print('ğŸµ Starting audio classification...');
      
      // é¢„å¤„ç†éŸ³é¢‘æ•°æ®
      var processedAudio = await _preprocessAudio(audioData);
      
      // è®¡ç®— mel é¢‘è°±å›¾
      var melSpectrogram = await _computeMelSpectrogram(processedAudio);
      
      // å‡†å¤‡æ¨¡å‹è¾“å…¥
      var input = _prepareModelInput(melSpectrogram);
      
      // è¿è¡Œæ¨ç†
      var output = await _runInference(input);
      
      // å¤„ç†è¾“å‡ºç»“æœ
      var results = _processOutput(output);
      
      return results;
    } catch (e) {
      print('âŒ Error classifying audio: $e');
      return [];
    }
  }

  /// é¢„å¤„ç†éŸ³é¢‘æ•°æ®
  Future<List<double>> _preprocessAudio(List<double> audioData) async {
    try {
      // ç¡®ä¿éŸ³é¢‘é•¿åº¦è¶³å¤Ÿ
      int minLength = 3 * _sampleRate; // è‡³å°‘3ç§’
      
      if (audioData.length < minLength) {
        // å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œç”¨é›¶å¡«å……
        audioData.addAll(List.filled(minLength - audioData.length, 0.0));
      } else if (audioData.length > minLength) {
        // å¦‚æœéŸ³é¢‘å¤ªé•¿ï¼Œå–ä¸­é—´éƒ¨åˆ†
        int start = (audioData.length - minLength) ~/ 2;
        audioData = audioData.sublist(start, start + minLength);
      }
      
      return audioData;
    } catch (e) {
      print('âŒ Error preprocessing audio: $e');
      rethrow;
    }
  }

  /// è®¡ç®— mel é¢‘è°±å›¾
  Future<List<List<double>>> _computeMelSpectrogram(List<double> audioData) async {
    try {
      List<List<double>> melSpectrogram = [];
      
      // è®¡ç®—å¸§æ•°
      int numFrames = (audioData.length - _frameSize) ~/ _hopSize + 1;
      
      for (int i = 0; i < numFrames; i++) {
        int start = i * _hopSize;
        int end = start + _frameSize;
        
        if (end > audioData.length) break;
        
        List<double> frame = audioData.sublist(start, end);
        List<double> windowedFrame = _applyHanningWindow(frame);
        List<double> fftResult = _computeFFT(windowedFrame);
        List<double> melFeatures = _computeMelFeatures(fftResult);
        
        melSpectrogram.add(melFeatures);
      }
      
      return melSpectrogram;
    } catch (e) {
      print('âŒ Error computing mel spectrogram: $e');
      rethrow;
    }
  }

  /// åº”ç”¨æ±‰å®çª—
  List<double> _applyHanningWindow(List<double> frame) {
    List<double> windowed = List.filled(frame.length, 0.0);
    
    for (int i = 0; i < frame.length; i++) {
      double windowValue = 0.5 * (1 - cos(2 * pi * i / (frame.length - 1)));
      windowed[i] = frame[i] * windowValue;
    }
    
    return windowed;
  }

  /// è®¡ç®— FFT
  List<double> _computeFFT(List<double> frame) {
    int n = frame.length;
    List<double> real = List.filled(n, 0.0);
    List<double> imag = List.filled(n, 0.0);
    
    for (int i = 0; i < n; i++) {
      real[i] = frame[i];
    }
    
    for (int k = 0; k < n; k++) {
      double sumReal = 0.0;
      double sumImag = 0.0;
      
      for (int j = 0; j < n; j++) {
        double angle = -2 * pi * k * j / n;
        sumReal += real[j] * cos(angle);
        sumImag += real[j] * sin(angle);
      }
      
      real[k] = sumReal;
      imag[k] = sumImag;
    }
    
    List<double> magnitude = List.filled(n ~/ 2, 0.0);
    for (int i = 0; i < n ~/ 2; i++) {
      magnitude[i] = sqrt(real[i] * real[i] + imag[i] * imag[i]);
    }
    
    return magnitude;
  }

  /// è®¡ç®— mel ç‰¹å¾
  List<double> _computeMelFeatures(List<double> fftResult) {
    List<double> melFeatures = List.filled(_numMels, 0.0);
    
    for (int i = 0; i < _numMels; i++) {
      double melEnergy = 0.0;
      
      for (int j = 0; j < fftResult.length; j++) {
        double melFilter = _getMelFilterValue(j, i, fftResult.length);
        melEnergy += fftResult[j] * melFilter;
      }
      
      melFeatures[i] = melEnergy > 0 ? log(melEnergy) : -20.0;
    }
    
    return melFeatures;
  }

  /// è·å– mel æ»¤æ³¢å™¨å€¼
  double _getMelFilterValue(int freqBin, int melBin, int numBins) {
    double centerFreq = melBin * _sampleRate / (2 * _numMels);
    double binFreq = freqBin * _sampleRate / (2 * numBins);
    
    double distance = (binFreq - centerFreq).abs();
    double bandwidth = _sampleRate / (4 * _numMels);
    
    if (distance < bandwidth) {
      return 1.0 - distance / bandwidth;
    }
    
    return 0.0;
  }

  /// å‡†å¤‡æ¨¡å‹è¾“å…¥
  List<List<List<double>>> _prepareModelInput(List<List<double>> melSpectrogram) {
    try {
      // YAMNet æœŸæœ›çš„è¾“å…¥å½¢çŠ¶é€šå¸¸æ˜¯ [1, frames, mel_bins]
      return [melSpectrogram];
    } catch (e) {
      print('âŒ Error preparing model input: $e');
      rethrow;
    }
  }

  /// è¿è¡Œæ¨¡å‹æ¨ç†
  Future<List<double>> _runInference(List<List<List<double>>> input) async {
    try {
      if (_interpreter == null) {
        throw Exception('Model not loaded');
      }
      
      // å‡†å¤‡è¾“å…¥å¼ é‡
      var inputTensor = _reshapeTo3D(input);
      
      // å‡†å¤‡è¾“å‡ºå¼ é‡
      var outputList = List<double>.filled(1 * _numClasses, 0.0);
      var outputTensor = outputList.reshape([1, _numClasses]);
      
      // è¿è¡Œæ¨ç†
      _interpreter!.run(inputTensor, outputTensor);
      
      return outputTensor[0].cast<double>();
    } catch (e) {
      print('âŒ Error running inference: $e');
      rethrow;
    }
  }

  /// é‡å¡‘ä¸º 3D å¼ é‡
  List<List<List<double>>> _reshapeTo3D(List<List<List<double>>> input) {
    if (input.isEmpty || input[0].isEmpty) {
      throw Exception('Empty input data');
    }
    
    int batchSize = 1;
    int frames = input[0].length;
    int features = input[0][0].length;
    
    List<List<List<double>>> reshaped = [];
    
    for (int b = 0; b < batchSize; b++) {
      List<List<double>> batch = [];
      for (int f = 0; f < frames; f++) {
        List<double> frame = [];
        for (int c = 0; c < features; c++) {
          frame.add(input[b][f][c]);
        }
        batch.add(frame);
      }
      reshaped.add(batch);
    }
    
    return reshaped;
  }

  /// å¤„ç†æ¨¡å‹è¾“å‡º
  List<MapEntry<String, double>> _processOutput(List<double> output) {
    try {
      List<MapEntry<String, double>> results = [];
      
      for (int i = 0; i < output.length && i < _labels!.length; i++) {
        double confidence = output[i];
        String label = _labels![i];
        
        if (confidence > 0.1) { // åªæ˜¾ç¤ºç½®ä¿¡åº¦å¤§äº0.1çš„ç»“æœ
          results.add(MapEntry(label, confidence));
        }
      }
      
      // æŒ‰ç½®ä¿¡åº¦æ’åº
      results.sort((a, b) => b.value.compareTo(a.value));
      
      // åªè¿”å›å‰10ä¸ªç»“æœ
      return results.take(10).toList();
    } catch (e) {
      print('âŒ Error processing output: $e');
      return [];
    }
  }

  /// æ¸…ç†èµ„æº
  void dispose() {
    try {
      _interpreter?.close();
      _recorder?.closeRecorder();
      print('ğŸ¯ YAMNet classifier disposed');
    } catch (e) {
      print('âŒ Error disposing YAMNet classifier: $e');
    }
  }
} 