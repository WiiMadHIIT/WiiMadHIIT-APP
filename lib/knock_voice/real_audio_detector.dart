import 'dart:async';
import 'dart:math';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'audio_session_config.dart';

/// Real Audio Detector for Voice Strike Detection
/// Uses flutter_sound onProgress for real-time amplitude detection
class RealAudioDetector {
  // State management
  bool _isInitialized = false;
  bool _isListening = false;
  
  // Audio recording
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  
  // Callbacks
  VoidCallback? onStrikeDetected;
  Function(String)? onError;
  Function(String)? onStatusUpdate;
  
  // Real-time amplitude detection
  StreamSubscription? _amplitudeSubscription;
  double _currentDb = 0.0; // å½“å‰åˆ†è´å€¼
  
  // Strike detection parameters
  static const double _dbThreshold = 30.0; // é™ä½åˆ†è´é˜ˆå€¼ï¼Œé€‚åº”iOSç¯å¢ƒ
  static const int _minStrikeInterval = 200; // æœ€å°å‡»æ‰“é—´éš”ï¼ˆæ¯«ç§’ï¼‰
  DateTime? _lastStrikeTime;
  
  // Hit counter
  int _hitCount = 0;
  
  /// Initialize detector with microphone permission
  Future<bool> initialize() async {
    try {
      // Check if already initialized
      if (_isInitialized) {
        _updateStatus('Real audio detector already initialized');
        print('ğŸ¯ Real audio detector already initialized');
        return true;
      }
      
      // iOS éŸ³é¢‘ä¼šè¯é…ç½®
      if (Platform.isIOS) {
        print('ğŸ¯ iOS: é…ç½®éŸ³é¢‘ä¼šè¯...');
        final sessionConfigured = await AudioSessionConfig.configureAudioSession();
        if (!sessionConfigured) {
          print('âš ï¸ iOS: éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•åˆå§‹åŒ–');
        }
      }
      
      // Initialize flutter_sound recorder
      print('ğŸ¯ Opening flutter_sound recorder...');
      await _recorder.openRecorder();
      print('ğŸ¯ Flutter_sound recorder opened successfully');
      
      _isInitialized = true;
      _updateStatus('Real audio detector initialized');
      print('ğŸ¯ Real audio detector initialized successfully');
      return true;
    } catch (e) {
      print('âŒ Failed to initialize real audio detector: $e');
      _handleError('Failed to initialize real audio detector: $e');
      return false;
    }
  }
  
  /// Start listening to microphone input with real-time amplitude detection
  Future<bool> startListening() async {
    if (!_isInitialized) {
      _handleError('Real audio detector not initialized');
      return false;
    }
    
    if (_isListening) {
      print('ğŸ¯ Audio detection already listening');
      return true;
    }
    
    try {
      // iOS é‡æ–°æ¿€æ´»éŸ³é¢‘ä¼šè¯
      if (Platform.isIOS) {
        print('ğŸ¯ iOS: é‡æ–°æ¿€æ´»éŸ³é¢‘ä¼šè¯...');
        await AudioSessionConfig.reactivate();
      }
      
      // Check if recorder is already recording
      if (_recorder.isRecording) {
        print('ğŸ¯ Recorder already recording, stopping first');
        await _recorder.stopRecorder();
      }
      
      // Get temporary directory for recording file
      final tempDir = await getTemporaryDirectory();
      final recordingPath = '${tempDir.path}/audio_detection_${DateTime.now().millisecondsSinceEpoch}.wav';
      
      print('ğŸ¯ Recording to file: $recordingPath');
      
      // iOS ä¼˜åŒ–çš„ç¼–è§£ç å™¨é™çº§ç­–ç•¥
      bool recordingStarted = false;
      
      // å°è¯•å¤šç§ç¼–è§£ç å™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
      final codecOptions = [
        {'codec': Codec.pcm16WAV, 'name': 'PCM16 WAV'},
        {'codec': Codec.pcm16, 'name': 'PCM16'},
        {'codec': Codec.aacADTS, 'name': 'AAC ADTS'},
        {'codec': Codec.aacMP4, 'name': 'AAC MP4'},
        {'codec': Codec.opusOGG, 'name': 'Opus OGG'},
        {'codec': Codec.opusCAF, 'name': 'Opus CAF'},
        {'codec': Codec.flac, 'name': 'FLAC'},
        {'codec': Codec.opusWebM, 'name': 'Opus WebM'},
        {'codec': Codec.vorbisOGG, 'name': 'Vorbis OGG'},
      ];
      
      for (final option in codecOptions) {
        try {
          print('ğŸ¯ Trying codec: ${option['name']}');
          
          await _recorder.startRecorder(
            toFile: recordingPath,
            codec: option['codec'] as Codec,
            sampleRate: 22050,    // iOS å…¼å®¹çš„é‡‡æ ·ç‡
            numChannels: 1,       // å•å£°é“ï¼Œå‡å°‘å¤„ç†è´Ÿæ‹…
            bitRate: 128000,      // é€‚ä¸­çš„æ¯”ç‰¹ç‡
            bufferSize: 512,      // è¾ƒå°çš„ç¼“å†²åŒºï¼Œé™ä½å»¶è¿Ÿ
          );
          
          print('âœ… Recording started successfully with ${option['name']} codec');
          recordingStarted = true;
          break;
          
        } catch (e) {
          print('âŒ Failed with ${option['name']}: $e');
          // ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªç¼–è§£ç å™¨
          continue;
        }
      }
      
      // å¦‚æœæ‰€æœ‰ç¼–è§£ç å™¨éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
      if (!recordingStarted) {
        print('âš ï¸ All codecs failed, trying default settings');
        try {
          await _recorder.startRecorder(
            toFile: recordingPath,
          );
          print('âœ… Recording started with default settings');
          recordingStarted = true;
        } catch (e) {
          print('âŒ Failed to start recording with default settings: $e');
          throw Exception('All recording methods failed: $e');
        }
      }
      
      _isListening = true;
      _updateStatus('Started listening to microphone');
      
      // ğŸ¯ è®¢é˜…å®æ—¶æŒ¯å¹…æ•°æ®
      _amplitudeSubscription = _recorder.onProgress!.listen((e) {
        _processAmplitudeData(e);
      });
      
      print('ğŸ¯ Real-time amplitude detection started successfully');
      return true;
    } catch (e) {
      print('âŒ Failed to start recording: $e');
      _handleError('Failed to start real audio detection: $e');
      return false;
    }
  }
  
  /// Stop listening
  Future<void> stopListening() async {
    if (!_isListening) return;
    
    try {
      // å–æ¶ˆæŒ¯å¹…è®¢é˜…
      await _amplitudeSubscription?.cancel();
      _amplitudeSubscription = null;
      
      // Only stop if actually recording
      if (_recorder.isRecording) {
        final recordingPath = await _recorder.stopRecorder();
        print('ğŸ¯ Recording stopped, file: $recordingPath');
        
        // Clean up the temporary file
        if (recordingPath != null) {
          try {
            final file = File(recordingPath);
            if (await file.exists()) {
              await file.delete();
              print('ğŸ¯ Temporary recording file cleaned up');
            }
          } catch (e) {
            print('âš ï¸ Failed to clean up recording file: $e');
          }
        }
      }
      
      _isListening = false;
      _updateStatus('Stopped listening to microphone');
      
      print('ğŸ¯ Real-time amplitude detection stopped');
    } catch (e) {
      _handleError('Failed to stop real audio detection: $e');
    }
  }
  
  /// ğŸ¯ å¤„ç†å®æ—¶æŒ¯å¹…æ•°æ®
  void _processAmplitudeData(RecordingDisposition e) {
    try {
      // è·å–å½“å‰åˆ†è´å€¼
      _currentDb = e.decibels ?? 0.0;
      
      // æ£€æµ‹å‡»æ‰“å£°éŸ³ï¼ˆé«˜æŒ¯å¹…è„‰å†²ï¼‰
      _checkStrikeFromAmplitude(_currentDb);
      
      // è°ƒè¯•ï¼šæ›´é¢‘ç¹åœ°è®°å½•åˆ†è´å€¼ï¼Œå¸®åŠ©è°ƒè¯•
      if (_hitCount % 3 == 0 || _currentDb > _dbThreshold * 0.8 || _currentDb > 10.0) { // æ¯3æ¬¡å‡»æ‰“ã€æ¥è¿‘é˜ˆå€¼æˆ–è¶…è¿‡10dBæ—¶è®°å½•
        print('ğŸ¤ Current dB: ${_currentDb.toStringAsFixed(1)} dB (threshold: $_dbThreshold)');
      }
      
    } catch (e) {
      print('âš ï¸ Amplitude processing error: $e');
    }
  }
  
  /// ğŸ¯ åŸºäºåˆ†è´å€¼æ£€æµ‹å‡»æ‰“å£°éŸ³
  void _checkStrikeFromAmplitude(double db) {
    final now = DateTime.now();
    
    // æ£€æŸ¥åˆ†è´å€¼æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if (db > _dbThreshold) {
      // æ£€æŸ¥æ—¶é—´é—´éš”
      if (_lastStrikeTime == null || 
          now.difference(_lastStrikeTime!).inMilliseconds > _minStrikeInterval) {
        
        _lastStrikeTime = now;
        _hitCount++;
        
        print('ğŸ¯ STRIKE DETECTED! dB: ${db.toStringAsFixed(1)} (threshold: $_dbThreshold), Count: $_hitCount');
        
        // è§¦å‘å‡»æ‰“æ£€æµ‹å›è°ƒ
        onStrikeDetected?.call();
      } else {
        // è®°å½•è¢«å¿½ç•¥çš„æ£€æµ‹ï¼ˆæ—¶é—´é—´éš”å¤ªçŸ­ï¼‰
        final timeSinceLast = now.difference(_lastStrikeTime!).inMilliseconds;
        print('âš ï¸ Strike ignored (too soon): dB ${db.toStringAsFixed(1)}, Time since last: ${timeSinceLast}ms (min: $_minStrikeInterval)');
      }
    }
  }
  
  /// Get listening status
  bool get isListening => _isListening;
  
  /// Get initialization status
  bool get isInitialized => _isInitialized;
  
  /// Get current decibel level
  double get currentDb => _currentDb;
  
  /// Get hit count
  int get hitCount => _hitCount;
  
  /// Reset hit count
  void resetHitCount() {
    _hitCount = 0;
    _lastStrikeTime = null;
    print('ğŸ¯ Hit count reset to 0');
  }
  
  /// Update status
  void _updateStatus(String status) {
    onStatusUpdate?.call(status);
  }
  
  /// Handle errors
  void _handleError(String error) {
    onError?.call(error);
  }
  
  /// Dispose resources
  void dispose() {
    try {
      stopListening();
      _amplitudeSubscription?.cancel();
      _recorder.closeRecorder();
      
      // iOS åœç”¨éŸ³é¢‘ä¼šè¯
      if (Platform.isIOS) {
        AudioSessionConfig.deactivate();
      }
      
      print('ğŸ¯ Real audio detector disposed');
    } catch (e) {
      _handleError('Error disposing real audio detector: $e');
    }
  }
}