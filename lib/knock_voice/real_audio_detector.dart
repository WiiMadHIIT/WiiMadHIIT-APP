import 'dart:async';
import 'dart:math';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';

/// Real Audio Detector for Voice Strike Detection
/// Uses flutter_sound with stream processing for real-time amplitude detection
class RealAudioDetector {
  // State management
  bool _isInitialized = false;
  bool _isListening = false;
  
  // Audio recording
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  
  // Callbacks
  VoidCallback? onStrikeDetected;
  Function(String)? onError;
  Function(String)? onStatusUpdate;
  
  // Real-time amplitude detection
  StreamSubscription? _amplitudeSubscription;
  StreamSubscription? _audioDataSubscription;
  double _currentDb = 0.0; // å½“å‰åˆ†è´å€¼
  
  // Strike detection parameters
  static const double _dbThreshold = 50.0; // é™ä½åˆ†è´é˜ˆå€¼ï¼Œé€‚åº”iOSç¯å¢ƒ
  static const int _minStrikeInterval = 200; // æœ€å°å‡»æ‰“é—´éš”ï¼ˆæ¯«ç§’ï¼‰
  DateTime? _lastStrikeTime;
  
  // Hit counter
  int _hitCount = 0;
  
  // Audio processing configuration
  static const int _sampleRate = 48000; // é‡‡æ ·ç‡
  static const int _numChannels = 1; // å•å£°é“
  static const int _bufferSize = 1024; // ç¼“å†²åŒºå¤§å°
  static const Duration _subscriptionDuration = Duration(milliseconds: 100); // è®¢é˜…é—´éš”
  
  // Audio data buffers for processing
  List<Float32List> _audioBuffer = [];
  final List<double> _amplitudeHistory = [];
  static const int _historySize = 10; // å†å²æ•°æ®å¤§å°
  
  // Stream controllers for audio data
  StreamController<List<Float32List>>? _audioDataController;
  StreamController<double>? _amplitudeController;
  
  /// Initialize detector with microphone permission
  Future<bool> initialize() async {
    try {
      // Check if already initialized
      if (_isInitialized) {
        _updateStatus('Real audio detector already initialized');
        print('ğŸ¯ Real audio detector already initialized');
        return true;
      }
      
      // Initialize flutter_sound recorder
      print('ğŸ¯ Opening flutter_sound recorder...');
      await _recorder.openRecorder();
      print('ğŸ¯ Flutter_sound recorder opened successfully');
      
      // Set subscription duration for real-time processing
      await _recorder.setSubscriptionDuration(_subscriptionDuration);
      print('ğŸ¯ Subscription duration set to ${_subscriptionDuration.inMilliseconds}ms');
      
      _isInitialized = true;
      _updateStatus('Real audio detector initialized');
      print('ğŸ¯ Real audio detector initialized successfully');
      return true;
    } catch (e) {
      print('âŒ Failed to initialize real audio detector: $e');
      _handleError('Failed to initialize real audio detector: $e');
      return false;
    }
  }
  
  /// Start listening to microphone input with real-time amplitude detection
  Future<bool> startListening() async {
    if (!_isInitialized) {
      _handleError('Real audio detector not initialized');
      return false;
    }
    
    if (_isListening) {
      print('ğŸ¯ Audio detection already listening');
      return true;
    }
    
    try {
      // Check if recorder is already recording
      if (_recorder.isRecording) {
        print('ğŸ¯ Recorder already recording, stopping first');
        await _recorder.stopRecorder();
      }
      
      // Clear previous data
      _audioBuffer.clear();
      _amplitudeHistory.clear();
      _hitCount = 0;
      _lastStrikeTime = null;
      
      // Get temporary directory for recording file
      final tempDir = await getTemporaryDirectory();
      final recordingPath = '${tempDir.path}/audio_detection_${DateTime.now().millisecondsSinceEpoch}.wav';
      
      print('ğŸ¯ Recording to file: $recordingPath');
      
      // Create stream controllers for audio data processing
      _audioDataController = StreamController<List<Float32List>>();
      _amplitudeController = StreamController<double>();
      
      // Start recording with flutter_sound using stream processing
      try {
        // Use PCM Float32 for better audio processing
        await _recorder.startRecorder(
          toFile: recordingPath,
          codec: Codec.pcmFloat32, // ä½¿ç”¨ Float32 æ ¼å¼è·å¾—æ›´å¥½çš„ç²¾åº¦
          sampleRate: _sampleRate,
          numChannels: _numChannels,
          audioSource: AudioSource.defaultSource,
          toStreamFloat32: _audioDataController!.sink, // ç›´æ¥å¤„ç†éŸ³é¢‘æ•°æ®æµ
          bufferSize: _bufferSize,
        );
        print('ğŸ¯ Recording started successfully with PCM Float32 stream');
      } catch (e) {
        print('âŒ Failed to start recording with PCM Float32: $e');
        try {
          // Fallback to AAC with amplitude monitoring
          await _recorder.startRecorder(
            toFile: recordingPath,
            codec: Codec.aacADTS,
            sampleRate: 22050,
            numChannels: _numChannels,
            bufferSize: _bufferSize,
          );
          print('ğŸ¯ Recording started with AAC fallback');
        } catch (e2) {
          print('âŒ Failed to start recording with fallback: $e2');
          rethrow;
        }
      }
      
      _isListening = true;
      _updateStatus('Started listening to microphone');
      
      // ğŸ¯ è®¢é˜…å®æ—¶æŒ¯å¹…æ•°æ®
      _amplitudeSubscription = _recorder.onProgress!.listen((e) {
        _processAmplitudeData(e);
      });
      
      // ğŸ¯ è®¢é˜…éŸ³é¢‘æ•°æ®æµï¼ˆå¦‚æœä½¿ç”¨ PCM Float32ï¼‰
      if (_audioDataController != null) {
        _audioDataSubscription = _audioDataController!.stream.listen((audioData) {
          _processAudioData(audioData);
        });
      }
      
      print('ğŸ¯ Real-time amplitude detection started successfully');
      return true;
    } catch (e) {
      print('âŒ Failed to start recording: $e');
      _handleError('Failed to start real audio detection: $e');
      return false;
    }
  }
  
  /// Stop listening
  Future<void> stopListening() async {
    if (!_isListening) return;
    
    try {
      // å–æ¶ˆæ‰€æœ‰è®¢é˜…
      await _amplitudeSubscription?.cancel();
      _amplitudeSubscription = null;
      
      await _audioDataSubscription?.cancel();
      _audioDataSubscription = null;
      
      // å…³é—­æµæ§åˆ¶å™¨
      await _audioDataController?.close();
      _audioDataController = null;
      
      await _amplitudeController?.close();
      _amplitudeController = null;
      
      // Only stop if actually recording
      if (_recorder.isRecording) {
        final recordingPath = await _recorder.stopRecorder();
        print('ğŸ¯ Recording stopped, file: $recordingPath');
        
        // Clean up the temporary file
        if (recordingPath != null) {
          try {
            final file = File(recordingPath);
            if (await file.exists()) {
              await file.delete();
              print('ğŸ¯ Temporary recording file cleaned up');
            }
          } catch (e) {
            print('âš ï¸ Failed to clean up recording file: $e');
          }
        }
      }
      
      _isListening = false;
      _updateStatus('Stopped listening to microphone');
      
      print('ğŸ¯ Real-time amplitude detection stopped');
    } catch (e) {
      _handleError('Failed to stop real audio detection: $e');
    }
  }
  
  /// ğŸ¯ å¤„ç†å®æ—¶æŒ¯å¹…æ•°æ®
  void _processAmplitudeData(RecordingDisposition e) {
    try {
      // è·å–å½“å‰åˆ†è´å€¼
      _currentDb = e.decibels ?? 0.0;
      
      // æ·»åŠ åˆ°å†å²è®°å½•
      _amplitudeHistory.add(_currentDb);
      if (_amplitudeHistory.length > _historySize) {
        _amplitudeHistory.removeAt(0);
      }
      
      // æ£€æµ‹å‡»æ‰“å£°éŸ³ï¼ˆé«˜æŒ¯å¹…è„‰å†²ï¼‰
      _checkStrikeFromAmplitude(_currentDb);
      
      // è°ƒè¯•ï¼šæ›´é¢‘ç¹åœ°è®°å½•åˆ†è´å€¼ï¼Œå¸®åŠ©è°ƒè¯•
      if (_hitCount % 3 == 0 || _currentDb > _dbThreshold * 0.8) {
        print('ğŸ¤ Current dB: ${_currentDb.toStringAsFixed(1)} dB (threshold: $_dbThreshold)');
      }
      
    } catch (e) {
      print('âš ï¸ Amplitude processing error: $e');
    }
  }
  
  /// ğŸ¯ å¤„ç†éŸ³é¢‘æ•°æ®æµï¼ˆPCM Float32ï¼‰
  void _processAudioData(List<Float32List> audioData) {
    try {
      // è®¡ç®—éŸ³é¢‘æ•°æ®çš„RMSèƒ½é‡
      double rmsEnergy = _calculateRMSEnergy(audioData);
      
      // è½¬æ¢ä¸ºåˆ†è´å€¼
      double dbFromAudio = _rmsToDecibels(rmsEnergy);
      
      // ä½¿ç”¨éŸ³é¢‘æ•°æ®è®¡ç®—çš„åˆ†è´å€¼ä½œä¸ºè¡¥å……æ£€æµ‹
      if (dbFromAudio > _dbThreshold * 1.2) { // ç¨å¾®æé«˜é˜ˆå€¼é¿å…è¯¯æ£€
        print('ğŸµ Audio data detected high energy: ${dbFromAudio.toStringAsFixed(1)} dB');
        _checkStrikeFromAudioData(dbFromAudio);
      }
      
    } catch (e) {
      print('âš ï¸ Audio data processing error: $e');
    }
  }
  
  /// ğŸ¯ è®¡ç®—RMSèƒ½é‡
  double _calculateRMSEnergy(List<Float32List> audioData) {
    if (audioData.isEmpty) return 0.0;
    
    double sum = 0.0;
    int count = 0;
    
    for (var channel in audioData) {
      for (var sample in channel) {
        sum += sample * sample;
        count++;
      }
    }
    
    if (count == 0) return 0.0;
    return sqrt(sum / count);
  }
  
  /// ğŸ¯ å°†RMSèƒ½é‡è½¬æ¢ä¸ºåˆ†è´å€¼
  double _rmsToDecibels(double rms) {
    if (rms <= 0.0) return -60.0; // æœ€å°åˆ†è´å€¼
    return 20.0 * log(rms) / ln10;
  }
  
  /// ğŸ¯ åŸºäºåˆ†è´å€¼æ£€æµ‹å‡»æ‰“å£°éŸ³
  void _checkStrikeFromAmplitude(double db) {
    final now = DateTime.now();
    
    // æ£€æŸ¥åˆ†è´å€¼æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    if (db > _dbThreshold) {
      // æ£€æŸ¥æ—¶é—´é—´éš”
      if (_lastStrikeTime == null || 
          now.difference(_lastStrikeTime!).inMilliseconds > _minStrikeInterval) {
        
        _lastStrikeTime = now;
        _hitCount++;
        
        print('ğŸ¯ STRIKE DETECTED! dB: ${db.toStringAsFixed(1)} (threshold: $_dbThreshold), Count: $_hitCount');
        
        // è§¦å‘å‡»æ‰“æ£€æµ‹å›è°ƒ
        onStrikeDetected?.call();
      } else {
        // è®°å½•è¢«å¿½ç•¥çš„æ£€æµ‹ï¼ˆæ—¶é—´é—´éš”å¤ªçŸ­ï¼‰
        final timeSinceLast = now.difference(_lastStrikeTime!).inMilliseconds;
        print('âš ï¸ Strike ignored (too soon): dB ${db.toStringAsFixed(1)}, Time since last: ${timeSinceLast}ms (min: $_minStrikeInterval)');
      }
    }
  }
  
  /// ğŸ¯ åŸºäºéŸ³é¢‘æ•°æ®æ£€æµ‹å‡»æ‰“å£°éŸ³
  void _checkStrikeFromAudioData(double db) {
    final now = DateTime.now();
    
    // ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼å’Œæ—¶é—´é—´éš”
    if (db > _dbThreshold * 1.2) {
      if (_lastStrikeTime == null || 
          now.difference(_lastStrikeTime!).inMilliseconds > _minStrikeInterval * 1.5) {
        
        _lastStrikeTime = now;
        _hitCount++;
        
        print('ğŸµ AUDIO STRIKE DETECTED! dB: ${db.toStringAsFixed(1)}, Count: $_hitCount');
        
        // è§¦å‘å‡»æ‰“æ£€æµ‹å›è°ƒ
        onStrikeDetected?.call();
      }
    }
  }
  
  /// Get listening status
  bool get isListening => _isListening;
  
  /// Get initialization status
  bool get isInitialized => _isInitialized;
  
  /// Get current decibel level
  double get currentDb => _currentDb;
  
  /// Get hit count
  int get hitCount => _hitCount;
  
  /// Get amplitude history
  List<double> get amplitudeHistory => List.from(_amplitudeHistory);
  
  /// Reset hit count
  void resetHitCount() {
    _hitCount = 0;
    _lastStrikeTime = null;
    print('ğŸ¯ Hit count reset to 0');
  }
  
  /// Update status
  void _updateStatus(String status) {
    onStatusUpdate?.call(status);
  }
  
  /// Handle errors
  void _handleError(String error) {
    onError?.call(error);
  }
  
  /// Dispose resources
  void dispose() {
    try {
      stopListening();
      _amplitudeSubscription?.cancel();
      _audioDataSubscription?.cancel();
      _audioDataController?.close();
      _amplitudeController?.close();
      _recorder.closeRecorder();
      print('ğŸ¯ Real audio detector disposed');
    } catch (e) {
      _handleError('Error disposing real audio detector: $e');
    }
  }
}